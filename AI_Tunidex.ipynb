{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Tunidex.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH_W0sgzjNGa"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lstbdipMjQYX",
        "outputId": "fc47e903-a723-4130-cde6-7041966e5f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mobile = tf.keras.applications.mobilenet.MobileNet()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iILqE1iUjQep"
      },
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHsINMBhjQl8",
        "outputId": "c45bfeda-5141-4726-b1f1-af894be5d485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "base_model=MobileNet(weights='imagenet' , input_shape=(224 , 224 , 3) ,include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
        "x=Dense(512,activation='relu')(x) #dense layer 3\n",
        "preds=Dense(2,activation='softmax')(x) #final layer with softmax activation"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiG_cUE8jQ0j"
      },
      "source": [
        "model=Model(inputs=base_model.input,outputs=preds)\n",
        "#specify the inputs\n",
        "#specify the outputs\n",
        "#now a model has been created based on our architecture"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq54F385jcpe"
      },
      "source": [
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GOBqFbHjc56"
      },
      "source": [
        "for layer in model.layers[:87]:\n",
        "    layer.trainable=False\n",
        "# or if we want to set the first 20 layers of the network to be non-trainable\n",
        "# for layer in model.layers[:20]:\n",
        "#     layer.trainable=False\n",
        "# for layer in model.layers[20:]:\n",
        "#     layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtqHmvLljc4M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6zupV4Ojc2A",
        "outputId": "4289e35b-b6d4-4325-e0d6-2820e18671af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/content/drive/My Drive/dataset/train',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 383 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbtS5O75jczo",
        "outputId": "56b1c946-8ae1-49c3-84bb-2595de52589a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train,\n",
        "                   epochs=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-9e786f543ef8>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/12\n",
            "11/11 [==============================] - 124s 11s/step - loss: 0.4797 - accuracy: 0.8466\n",
            "Epoch 2/12\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 0.0923 - accuracy: 0.9573\n",
            "Epoch 3/12\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.0247 - accuracy: 0.9943\n",
            "Epoch 4/12\n",
            "11/11 [==============================] - 1s 104ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 5/12\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 6/12\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 5.3456e-04 - accuracy: 1.0000\n",
            "Epoch 7/12\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 3.1704e-05 - accuracy: 1.0000\n",
            "Epoch 8/12\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 2.3756e-05 - accuracy: 1.0000\n",
            "Epoch 9/12\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 1.0825e-05 - accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "11/11 [==============================] - 1s 98ms/step - loss: 2.7947e-06 - accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 9.4831e-07 - accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 6.8076e-07 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f867e6fdda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTHtrLcKjvTx",
        "outputId": "3f0c097d-d4af-42ac-d88a-292c1eafc46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "validation_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "validation_generator=validation_datagen.flow_from_directory('/content/drive/My Drive/dataset/validation',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 96 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuQnDXjjjvNO",
        "outputId": "3ff50964-d150-48f8-a53f-389fc7b7379f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred = model.evaluate(validation_generator , steps=12)\n",
        "model.metrics_names\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 3s 115ms/step - loss: 0.0437 - accuracy: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04370713233947754, 0.9895833134651184]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSxoHIMpuzLS"
      },
      "source": [
        "# save the model to tflite format\n",
        "keras_file = \"AI_Tunidex\"\n",
        "tf.saved_model.save(model, keras_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X41V5pTlKOrD"
      },
      "source": [
        "# # load the file\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(keras_file)\n",
        "# tflite_model = converter.convert()\n",
        "# open(\"AI_Tunidex.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}